{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Scikit-Learn 快速實作\n",
    "\n",
    "## 郭耀仁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 什麼是 Scikit-Learn\n",
    "\n",
    "- 用來實作資料探勘與機器學習的 Python 套件\n",
    "- 建構於 NumPy，SciPy 與 Matplotlib 套件之上\n",
    "- 有六大功能模組：\n",
    "    - 預處理\n",
    "    - 降維\n",
    "    - 迴歸\n",
    "    - 分群\n",
    "    - 分類\n",
    "    - 模型選擇"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 什麼是 Scikit-Learn（2）\n",
    "\n",
    "- [其他的 Scikits](https://scikits.appspot.com/scikits)\n",
    "- [Scikit-Learn 機器學習地圖](http://scikit-learn.org/stable/tutorial/machine_learning_map/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 內建資料\n",
    "\n",
    "- 玩具資料（Toy datasets）：<http://scikit-learn.org/stable/datasets/index.html#toy-datasets>\n",
    "- `datasets` 模組\n",
    "\n",
    "```python\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(X[0:5, :])\n",
    "print(y[0:5])\n",
    "print(np.unique(y))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 切分訓練與測試資料\n",
    "\n",
    "- `cross_validation` 模組的 `train_test_split()` 方法\n",
    "- `test_size = ` 參數設定切分比例\n",
    "- `random_state = ` 參數設定隨機種子\n",
    "\n",
    "```python\n",
    "from sklearn import datasets, cross_validation\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 正規化\n",
    "\n",
    "- `preprocessing.StandardScaler` 模組的 `transform()` 方法\n",
    "\n",
    "```python\n",
    "from sklearn import datasets, cross_validation, preprocessing\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "sc = preprocessing.StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "print(X_train_std[0:5, :])\n",
    "print(X_test_std[0:5, :])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 訓練與預測（感知器模型）\n",
    "\n",
    "- `linear_model` 模組的 `Perceptron()` 方法\n",
    "\n",
    "```python\n",
    "from sklearn import datasets, cross_validation, preprocessing, linear_model\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "sc = preprocessing.StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "ppn = linear_model.Perceptron(n_iter = 40, eta0 = 0.1, random_state = 87)\n",
    "ppn.fit(X_train_std, y_train)\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "mis_classified = (y_test != y_pred).sum()\n",
    "print(\"Misclassified samples: %d\" %mis_classified)\n",
    "error_rate = mis_classified/len(y_pred)\n",
    "print(\"Accuracy: %f\" %(1 - error_rate))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型評估\n",
    "\n",
    "- `metrics` 模組的 `accuracy_score()` 方法\n",
    "\n",
    "```python\n",
    "from sklearn import datasets, cross_validation, preprocessing, linear_model, metrics\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "sc = preprocessing.StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "ppn = linear_model.Perceptron(n_iter = 40, eta0 = 0.1, random_state = 87)\n",
    "ppn.fit(X_train_std, y_train)\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %0.2f\" %accuracy)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 視覺化\n",
    "\n",
    "```python\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_decision_regions(X, y, classifier):\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[len(np.unique(y))])\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max), np.arange(x2_min, x2_max))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha = 0.4, cmap = cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x = X[y == cl, 0], y = X[y == cl, 1], alpha = 0.8, c = cmap(idx), marker = markers[idx], label = cl)\n",
    "\n",
    "X = iris.data[:, [0, 2]]\n",
    "y = iris.target\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, test_size = 0.3, random_state = 87)\n",
    "sc = preprocessing.StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "ppn = linear_model.Perceptron(n_iter = 40, eta0 = 0.1, random_state = 87)\n",
    "ppn.fit(X_train_std, y_train)\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "plot_decision_regions(X = X, y = y, classifier = ppn)\n",
    "plt.show()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
